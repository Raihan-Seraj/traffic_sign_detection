{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution neural networks for classifying different traffic signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can comment the two lines below if you have python opencv and numpy 1.21.2 already installed. \n",
    "!pip install opencv-python\n",
    "!pip install numpy==1.21.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt ## plotting library\n",
    "import pandas as pd ## data management and reading library\n",
    "import random ## module handling random numbers\n",
    "from sklearn.model_selection import train_test_split ## module for splitting the dataset into training and testing examples\n",
    "import csv ## module for importing the csv files\n",
    "import pdb ## importing the python debugger in case of debugging the code\n",
    "#import resizeimage ## module for resizing image \n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the image dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps to read the image dataset and converts them to list of images and the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 43 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading the image dataset\n",
    "path_of_data=('GTSRB/Training/Images')## path of where the dataset is stored\n",
    "images,labels=readTrafficSigns(path_of_data)## reading the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image processing step involves converting the colored image into gray scale as well as transforming all the images in a common scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_image=[]\n",
    "for items in images:\n",
    "    img_gray = cv2.cvtColor(items, cv2.COLOR_BGR2GRAY)\n",
    "    grey_image.append(img_gray)\n",
    "\n",
    "## resizing the grayscale images:\n",
    "resized_grey_image=[]\n",
    "for items in grey_image:\n",
    "    resized_grey_image.append(cv2.resize(items, (64, 64), interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showing an example in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_grey_image[1000], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## displaying the distribution of the classes in the dataset \n",
    "z=Counter(labels)## counts how many examples are there for each labels\n",
    "y_pos=range(43)# there are 43 labels so creating an array from 0:42\n",
    "plt.bar(y_pos,list(z.values()))#plotting the bar\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Training Examples')\n",
    "plt.show()#showing the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##flattening the image matrix, converting each 64 by 64 matrix to a single length array\n",
    "processed_images=np.zeros([len(labels),(64*64)])\n",
    "idx=0\n",
    "for items in resized_grey_image:\n",
    "    \n",
    "    processed_images[idx]=(items.flatten())\n",
    "    idx+=1\n",
    "print('Yaba daba du Image Processed !!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the dataset and splitting the dataset into Training and the Test set\n",
    "The datasets are shuffled in order to reduce the class imbalance and the data is split into training and the test set. With 70% of the data used for training and 30% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(processed_images, labels, test_size=0.3, random_state=0) ## ranom state fixes the seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN architecture and module\n",
    "Now the dataset is processed for feeding in the examples in a convolution neural network we start initially with a 4 layer network, where we used Batch normalisation in order to reduce the overfitting. We used Rectification Linear Unit (RELU) activation function for the nodes. Finally in order to use adaptive learning rates we have chosen ADAM optimizer in order to optimize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(2))\n",
    "             \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=5, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc = nn.Linear(4096,43)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        #out=self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convering all the arrays and lists into Tensors to that has to be fed in the model \n",
    "In this part we will be converting all the arrays and the list of examples for both the training and the test dataset to tensors, after that we can only feed everythin into the neural network module \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=120\n",
    "\n",
    "\n",
    "train_set=X_train.astype(np.float32).reshape(-1,1,64,64)\n",
    "test_set=X_test.astype(np.float32).reshape(-1,1,64,64)\n",
    "\n",
    "X_train=torch.Tensor(train_set)\n",
    "X_test=torch.Tensor(test_set)\n",
    "y_train=np.array(y_train)\n",
    "y_train=y_train.astype(np.float32)\n",
    "y_train=torch.Tensor(y_train)\n",
    "\n",
    "y_test=np.array(y_test)\n",
    "y_test=y_test.astype(np.float32)\n",
    "y_test=torch.Tensor(y_test)\n",
    "train=torch.utils.data.TensorDataset(X_train,y_train)\n",
    "test=torch.utils.data.TensorDataset(X_test,y_test)\n",
    "train_set_dataloader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=False)\n",
    "test_set_dataloader=torch.utils.data.DataLoader(dataset=test,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=13\n",
    "train_accu=[]\n",
    "cnn = CNN()## loading the cnn class constructed above\n",
    "cnn.train()\n",
    "if torch.cuda.is_available():\n",
    "    cnn.cuda() ## using the gpu in the system, do not worry if your system does not have the gpu it will automatically select cpu\n",
    "all_loss=[]\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_set_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "        #print(images.size())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        #pdb.set_trace():\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        outputs = cnn(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "                         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "       # prediction = outputs.data.max(1)[1]   # first column has actual prob.\n",
    "        #accuracy = prediction.eq(labels.data).sum()/batch_size*100\n",
    "        #train_accu.append(accuracy)\n",
    "        #if i % 1000 == 0:\n",
    "         #   print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(i, loss.data[0], accuracy))\n",
    "        #i += 1\n",
    "        if (i+1) % 100 == 0:\n",
    "          \n",
    "            all_loss.append(loss.data)\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_loss)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('CNN loss with number of Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
